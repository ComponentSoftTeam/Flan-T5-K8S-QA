# Flan-T5-K8S-QA
Fine-tuning a Flan-T5 model for question answering based on question answering data in the K8S topic.

## Dataset
We used a dataset generated by the subproject `kubeget` that scrapes the official documentation for kubectl and augments the gathered data using the openai GPT APIs.  
You can find the dataset on huggingface [here](https://huggingface.co/datasets/Kristofy/k8s-kubectl)

## Notebooks
We tried two methods for finetuning a flan-t5 model, one with basic question answering, and the other with providing a chain of thought process.  


| Method          | Notebook                                       |
| --------------- | ---------------------------------------------- |
| Normal QA     | [Open Notebook](https://colab.research.google.com/github/tmskss/Flan-T5-K8S-QA/blob/main/notebooks/flan_t5_k8s.ipynb) |
| CoT QA  | [Open Notebook](https://nbviewer.jupyter.org/github/tmskss/Flan-T5-K8S-QA/blob/main/notebooks/flan_t5_k8s_cot.ipynb)  |
